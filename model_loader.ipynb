{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "rc = {\"axes.spines.left\" : False,\n",
    "      \"axes.spines.right\" : False,\n",
    "      \"axes.spines.bottom\" : False,\n",
    "      \"axes.spines.top\" : False,\n",
    "      \"xtick.bottom\" : False,\n",
    "      \"xtick.labelbottom\" : False,\n",
    "      \"ytick.labelleft\" : False,\n",
    "      \"ytick.left\" : False}\n",
    "plt.rcParams.update(rc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "file = open('test_data.pkl', 'rb')\n",
    "\n",
    "test_image, test_label = pickle.load(file)\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive E is Dipbridge\n",
      " Volume Serial Number is 30AF-14CC\n",
      "\n",
      " Directory of E:\\Code\\VideoHumanClassification\\models\n",
      "\n",
      "13/10/2019  16:50           922.888 l2388-a90-13102019-1650.h5\n",
      "               1 File(s)        922.888 bytes\n",
      "\n",
      " Directory of E:\\Code\\VideoHumanClassification\\models\\pretrained1\\12102019-0123\n",
      "\n",
      "12/10/2019  01:24         1.928.824 l2745-a89-12102019-0123.h5\n",
      "               1 File(s)      1.928.824 bytes\n",
      "\n",
      " Directory of E:\\Code\\VideoHumanClassification\\models\\pretrained1\\12102019-0136\n",
      "\n",
      "12/10/2019  01:37         1.046.784 l2726-a88-12102019-0136.h5\n",
      "12/10/2019  01:37         1.046.784 l2745-a89-12102019-0136.h5\n",
      "12/10/2019  01:37         1.046.784 l2815-a88-12102019-0136.h5\n",
      "               3 File(s)      3.140.352 bytes\n",
      "\n",
      " Directory of E:\\Code\\VideoHumanClassification\\models\\pretrained1\\12102019-0139\n",
      "\n",
      "12/10/2019  01:41           631.016 l2793-a89-12102019-0139.h5\n",
      "12/10/2019  01:40           631.016 l2807-a89-12102019-0139.h5\n",
      "12/10/2019  01:40           631.016 l2844-a88-12102019-0139.h5\n",
      "12/10/2019  01:40           631.016 l2887-a87-12102019-0139.h5\n",
      "               4 File(s)      2.524.064 bytes\n",
      "\n",
      " Directory of E:\\Code\\VideoHumanClassification\\models\\pretrained1\\13102019-0110\n",
      "\n",
      "13/10/2019  01:10         1.270.536 l2755-a89-13102019-0110.h5\n",
      "13/10/2019  01:10         1.270.536 l2822-a89-13102019-0110.h5\n",
      "               2 File(s)      2.541.072 bytes\n",
      "\n",
      " Directory of E:\\Code\\VideoHumanClassification\\models\\pretrained1\\13102019-0116\n",
      "\n",
      "13/10/2019  01:16         2.386.576 l2735-a89-13102019-0116.h5\n",
      "13/10/2019  01:16         2.386.576 l2895-a88-13102019-0116.h5\n",
      "13/10/2019  01:16         2.386.576 l2974-a87-13102019-0116.h5\n",
      "               3 File(s)      7.159.728 bytes\n",
      "\n",
      " Directory of E:\\Code\\VideoHumanClassification\\models\\pretrained1\\13102019-0118\n",
      "\n",
      "13/10/2019  01:18         4.617.648 l2746-a89-13102019-0118.h5\n",
      "               1 File(s)      4.617.648 bytes\n",
      "\n",
      " Directory of E:\\Code\\VideoHumanClassification\\models\\pretrained1\\13102019-0133\n",
      "\n",
      "13/10/2019  01:33           621.808 l2578-a90-13102019-0133.h5\n",
      "               1 File(s)        621.808 bytes\n",
      "\n",
      " Directory of E:\\Code\\VideoHumanClassification\\models\\pretrained1\\13102019-0204\n",
      "\n",
      "13/10/2019  02:05           621.808 l2555-a90-13102019-0204.h5\n",
      "               1 File(s)        621.808 bytes\n",
      "\n",
      " Directory of E:\\Code\\VideoHumanClassification\\models\\pretrained2\\13102019-0913\n",
      "\n",
      "13/10/2019  09:14           621.800 l2513-a89-13102019-0913.h5\n",
      "               1 File(s)        621.800 bytes\n",
      "\n",
      " Directory of E:\\Code\\VideoHumanClassification\\models\\pretrained2\\13102019-0917\n",
      "\n",
      "13/10/2019  09:19           621.800 l2406-a91-13102019-0917.h5\n",
      "13/10/2019  09:18           621.800 l2497-a90-13102019-0917.h5\n",
      "               2 File(s)      1.243.600 bytes\n",
      "\n",
      "     Total Files Listed:\n",
      "              20 File(s)     25.943.592 bytes\n",
      "               0 Dir(s)  184.864.325.632 bytes free\n"
     ]
    }
   ],
   "source": [
    "!dir /S *.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_33 (Conv2D)           (None, 78, 48, 16)        448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_33 (MaxPooling (None, 39, 24, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 37, 22, 16)        2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_34 (MaxPooling (None, 18, 11, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, 16, 9, 32)         4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_35 (MaxPooling (None, 8, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 64)                65600     \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 73,073\n",
      "Trainable params: 73,073\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Recreate the exact same model, including its weights and the optimizer \n",
    "model_dir = './models/20102019-0940/' + 'l2883-a88-20102019-0940.h5'\n",
    "model = keras.models.load_model(model_dir, custom_objects={'leaky_relu': tf.nn.leaky_relu})\n",
    "\n",
    "# Show the model architecture \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1671/1671 [==============================] - 1s 402us/step\n",
      "Loss: 0.44140436774524366, Accuracy: 0.8533812088926419\n"
     ]
    }
   ],
   "source": [
    "image_size_y = 50\n",
    "image_size_x = 80\n",
    "\n",
    "test_image = test_image.reshape(len(test_image), image_size_x, image_size_y, 3)\n",
    "test_image = test_image / 255.0\n",
    "\n",
    "test_loss = model.evaluate(test_image, test_label)\n",
    "print(\"Loss: {}, Accuracy: {}\".format(test_loss[0], test_loss[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifications = model.predict(test_image)\n",
    "\n",
    "import random\n",
    "\n",
    "curr_start = random.randint(0, 1000)\n",
    "curr_end = curr_start + 10\n",
    "for preview in range(2):\n",
    "    idx = [x for x in range(curr_start, curr_end)]\n",
    "\n",
    "    fig, axs = plt.subplots(2, 5)\n",
    "\n",
    "    count = 0\n",
    "    for i in range(2):\n",
    "        for j in range(5):\n",
    "            axs[i, j].imshow(test_image[idx[count]])\n",
    "            prob = classifications[idx[count]]\n",
    "            axs[i, j].set_title('{:.2f}'.format(prob.item()))\n",
    "            count += 1\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    curr_end += 10\n",
    "    curr_start += 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axarr = plt.subplots(3,4)\n",
    "\n",
    "FIRST_IMAGE= random.randint(0, 1000)\n",
    "SECOND_IMAGE= random.randint(0, 1000)\n",
    "THIRD_IMAGE= random.randint(0, 1000)\n",
    "CONVOLUTION_NUMBER = 2\n",
    "\n",
    "from tensorflow.keras import models\n",
    "\n",
    "layer_outputs = [layer.output for layer in model.layers]\n",
    "activation_model = tf.keras.models.Model(inputs = model.input, outputs = layer_outputs)\n",
    "for x in range(0,4):\n",
    "  f1 = activation_model.predict(test_image[FIRST_IMAGE].reshape(1, image_size_x, image_size_y, 3))[x]\n",
    "  axarr[0,x].imshow(f1[0, : , :, CONVOLUTION_NUMBER], cmap='gray_r')\n",
    "  axarr[0,x].grid(False)\n",
    "  f2 = activation_model.predict(test_image[SECOND_IMAGE].reshape(1, image_size_x, image_size_y, 3))[x]\n",
    "  axarr[1,x].imshow(f2[0, : , :, CONVOLUTION_NUMBER], cmap='gray_r')\n",
    "  axarr[1,x].grid(False)\n",
    "  f3 = activation_model.predict(test_image[THIRD_IMAGE].reshape(1, image_size_x, image_size_y, 3))[x]\n",
    "  axarr[2,x].imshow(f3[0, : , :, CONVOLUTION_NUMBER], cmap='gray_r')\n",
    "  axarr[2,x].grid(False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
